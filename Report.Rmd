---
title: Estimating Pro-War and Anti-War Sentiments by State Using Multilevel Regression with Poststratification
author: "Parker Kaukl"
date: 5/17/2022
output:
  pdf_document: default
  html_document:
    df_print: paged
fontsize: 11pt
indent: true

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, fig.height=4, fig.width=6)
# feel free to change fig.height or fig.width here or in specific chunk headings. 
```



```{r, include=FALSE}
library(tidyverse)
library(knitr)
library(lme4)
library(lmerTest)
library(gridExtra)
library(corrplot)
library(GGally)
library(kableExtra)
library(arm)
library(usmap)
library(dplyr)
library(tidycensus)
library(stargazer)
library(coda)
library(rstanarm)
library(bayesplot)
library(stringr)
library(ggrepel)
```


```{r}
 load("Workspace.RData") # This is data that had previously been collected from the previous files.
```
## Abstract

One of the most complex topics in american politics is military intervention. Public opinion on military intervention is historically divided into pro-war and anti-war positions. Understanding which states may be more or less likely to be pro or anti War is important for predicting which areas may have more protests, and inform policy positions for elected officials. This paper will create a model to predict opinions on war using a Frequentist and a Bayesian approach. Then, these models will be used in order to create a Multilevel Regression with Post-Stratification to estimate the public opinion within each state in the United States of America. In both the Bayesian and the Frequentist approaches, our Multilevel Regression with Post-Stratification estimates that the public opinion within each state to believe that War is effective is between 60% and 70%. These results tend to be similar to the public opinion polls on war, before any casualties have been incurred.

\newpage


### Introduction


The decision to go to war is a complex decision that has severe consequences. A report from Brown University estimated that around 900,000 deaths occurred in the War on Terror. These fatalities  include soldiers, civilians, journalists and aid workers.In addition, the U.S.'s War on Terror has incurred a cost of $8 trillion dollars since 2001. Because of these high societal costs, it is not surprising that conflict tends to be a polarizing topic, and a topic that has attracted theories on when conflict may occur. 

One of the first theories of War is the "Just War" theory, by St. Augustine. This posited that conflict should occur if it is for a worthy cause, if conflict is likely to achieve that cause and if the conflict is sponsored by a legitimate government. "Just War" theory also states that conflict should only be used as a last resort, that conflict should not be disproportionate to the cause, and that non-combatants should be respected. Although this theory is valuable, the discourse on military conflict has been furthered by philosophers, politicians, and theologians over the past centuries. 

However, perhaps the most relevant and important influence on our perception of war has been the United State's recent history of war. A lot of theories and thoughts on war were developed in the aftermath of the Vietnam War. As noted in Richard Haas's book, Intervention, the Vietnam War was an event that informs both our policymakers and citizens on what War is like. Perhaps more importantly, the Vietnam War and the protests related to U.S. involvement introduced the importance of U.S. public opinion to whether we should engage in military conflicts. 

Caspar Weinberger, a Secretary of Defense under Ronald Reagan, introduced the Weinberger Doctrine, which stated that force should only be used if there is public or congressional support for military conflict. This was furthered by Warren Christopher, the Secretary of Defense under Bill Clinton, who said that having "a high likelihood of support" of popular and congressional support was a prerequisite for military intervention. Other Politicians have not mentioned public opinion as a prerequisite, but have mentioned that it is desirable to have support for any military intervention. 

The Effects of Public Opinion during Wartime are numerous. As noted by George Gallup, Public Opinion can often coincide with political changes. As stated in _How Important is Public Opinion in Time of War?_, "In addition to conscription, the people of this country have been ahead of their political leaders on virtually all important war-time issues" (Gallup, 441). In addition, conflict is often likely to not occur, or forces are likely to be withdrawn in the case of public disapproval. This can be seen in a lack of approval for U.S. intervention in Somalia, and later the U.S.'s lack of military intervention in Rwanda during the Rwanda Genocide. In addition, the mismanagement of military intervention threatens re-election campaigns for politicians. Because of this threat, "Politicians--Whose foremost goal is to gain or retain office- will, in an electoral context, be motivated to support changes in war policy if opinion trends among their constituents offer an incentive to do so" (Lieberfeld, 2008). Public Opinion acts as a political constraint to the use of force, in addition to providing probable policy platforms during upcoming elections. 

For policymakers, understanding public opinion is crucial to making the correct decision about when it is appropriate to use military force. In addition, for citizens, public opinion can provide a good predictor of future policy decisions. Therefore, this paper will attempt to create a Frequentist and a Bayesian model in order to estimate the public opinion on military intervention based off a series of surveys known as the *Chicago Council Survey of American Public Opinion on U.S.Foreign Policy* from 2016 and 2017. The Survey question that we will analyze focuses on the public opinion on the effectiveness of war in achieving the foreign policy goals of the United States. Using this data, we will estimate the expected political support in each U.S. state in 2016 and 2017. This will be done using a method known as Multilevel Regression with Post-stratification, using data from the American Community Survey. Then, this paper will attempt to validate these models by checking that there are no errors in this model, and doing model validation.  

### Background and Significance

There have been numerous opinion polls and regressions that have been run in order to estimate pro or anti war opinion during the "post cold war" era. There are a few reasons why authors and academics tend to start their analysis of war trends in the "post cold war" era. In general, the individual's personal policy preference on war tends to be very temporal. The cold war provided a very unique circumstance, such as the policy of deterrence and the fear of a global war, that does not necessarily reflect the current circumstances of conflicts in the "post cold war" era. Because of this, our scholarship tends to focus on the "post cold war" era as a separate era to the cold war era. 

According to Gelpi and Feaver, the determination of a citizen's preference is based on that individual's demographics, and the context of the situation. Specifically, individuals tend to be in support of military intervention if they believe that they have the "Right" to attack, and they believe that military intervention will be successful to achieve their preferred policy goals. Many of these contextual results are likely to reflect incredibly temporal events that are vulnerable to political changes. For instance, individuals tend to look towards individuals such as politicians that they trust, and organizations such as NATO. If an organization like NATO, or a president that they trust endorse a military action, individuals are extremely likely to support that military interaction. This was found by both Olga Khazan(2013) and by Gelpi and Feaver(2009). 

In addition, individuals are likely to make choices depending on the Principal Policy Objective, according to Jentleson (1992). This thesis argues that individuals have different values, and that the primary objective of why is going to war is likely to influence the level of political support for intervention. For instance, according to a poll from Jentleson, individuals tend to be more in support of Foreign Policy Restraint missions, as opposed to Internal Political Change missions. Foreign Policy Restraint typically involves the use of military force in order to affect the behavior of a nation, whereas Internal Political Change Missions involve using the military to replace or restructure an existing regime. 

Finally, individuals also tend to support missions that they believe will be successful. As noted by Gelpi and Feaver (2009), public support for military intervention tends to drastically decreasing during periods of failure. For instance, In the aftermath of a failed raid in Somalia in 1993, public support for military intervention dropped by 8 percentage points. In general, individuals tend to support a war when there is evidence that there is some level of success. 

While these circumstantial predictors are important, there are additional variables that might be important in order to predict pro vs. antiwar sentiment. These variables are demographic, and tend to be less dependent on the context of the conflict in determining public opinion. For instance, our evidence of gender suggests that there is a mixed effect of whether women or men are more supportive of conflict. Gelpi and Feaver wrote *Paying the Human Costs of War*, which collects regressions that indicate that there is conflicting evidence about the effect of gender in being pro or antiwar. Men were more supportive of military intervention in Lebanon in 1983. Men also tended to be more supportive of military intervention in Somalia in 1993. In the early 2000s, a general poll reported by Gelpi and Feaver stated that there was no statistical significance in gender in determining whether an individual supports military intervention. However, evidence from polls taken during the Kosovo crisis suggests that Women were more likely to support military intervention through Air strikes in the Kosovo War. Women were also more likely to fall into the category that Gelpi and Feaver refer to as "Timid Hawks". Gelpi and Feaver use this term to classify individuals who are supportive of War in the abstract, but tend to withdraw their support as the war becomes costly, or as casualties from the conflict increase. This is also important to note, as it highlights a major theme of Gelpi and Feaver, which is that casualty tolerance is not the same thing as conflict tolerance. 


Another variable that is very important to consider is age. Anecdotally, there is evidence that suggests that age can both increase and decrease support for War. Many historians note the fervor that younger men tended to have, and their excitement for World War 1. Meanwhile, Vietnam War Era protests are remembered for the swarms of college students who protested against the U.S's involvement in Southeast Asia. However, data tends to provide a conflicted history of who tends to be more pro war. Older individuals were less likely to support a military intervention in Lebanon and in Somalia. However, older individuals were less likely to support the Iraq War (Smith and Lindsay, 2003). However, age did not appear to play any significant role in whether an individual supported intervention in the Kosovo War. In general, the role that age plays in determining pro and anti war support appears to be inconsistent. 

The role of education in determining pro and anti war stance tends to be very consistent. These estimates tend to suggest that individuals with higher levels of education may be less likely to support war. People were less likely to support a military intervention in Kosovo with higher levels of education. In addition, people with higher levels of education were less likely to support the use of force if the objective of the mission is a matter of national security. However, education did not have a significant change for whether an individual supported military intervention in Yemen or in Lebanon. In addition, according to Smith and Lindsay (2003), education plays a major role in determining support. Individuals with a postgraduate education were among the few groups who were not in favor of the Iraq War in late 2002. 

There are many different additional variables that might be important in determining which individuals will support or not support a war. For instance, people tend to support a war if that war was initiated by the party that aligns with their own personal politics. For instance, democrats tend to be more supportive of military intervention if a democratic president initiated that war, and republican voters are more likely to support wars initiated during a republican presidency. In addition, individuals who are veterans tend to be less likely to support military intervention, as found by Khazan (2013). The affect of other demographic variables, such as Race, tend to have inconsistent evidence on the direction and the significance of the effect of racial identity on pro and antiwar stance. 




### Data

The first dataset that I used was the Chicago Council Survey of American Public Opinion on U.S. Foreign Policy. This is an annual survey that asks questions related to the foreign policies in the United States, and the public opinion on these policies. For the purpose of my data, I am using the 2016 and 2017 Chicago Council Survey of American public Opinion. These two years were used because they are both publically available, and they both have a question that is coded the same. The target population of this survey was those living in the U.S. who were non-institutionalized and who are aged over 18. The survey was administered by the KnowledgePanel, which is a probability based web panel designed to be representative of the U.S. results. The administrators of this survey included various checks, such as removing those who answered the test too quick and those who failed the "quality checks". The "quality checks" consisted of questions such as "Pick option 3", which indicates whether a respondent was actually attentive during the survey. The Chicago Council Survey has 4767 observations over the 2 years. 

In order to clean this data, we took multiple steps. First, any cases where there was a missing value were discarded, in order to prevent any bias that might occur by keeping these variables in the dataset. In addition, many of the variables were manipulated in order to create new variables for the purpose of a regression. Initially, there was a variable called *Q8_14*. This variable recorded the respondents answer to the question *How effective do you think each of the following approaches are to achieving the foreign policy goals of the United States- very effective, somewhat effective, not very effective, or not effective at all: Intervening Militarily*. Using this variable, we manipulated it into a new variable called *ProWarBinary*. If this variable is equal to 1, then the respondent believes that military intervention is either very effective or somewhat effective. Meanwhile, if the respondent believes that military intervention is not very effective or not effective at all, then the variable will return with a value of 0. 

In addition, the Chicago Foreign Council data also had additional variables that reflect the demographics of the respondents. In this case, the variables includes information about the racial, political, social, economic and family history of the respondent. There are a few variables of note that will later be used in the model to build the Multilevel Regression with Post stratification. The variable *EducationBracket3* represents a subset of different levels of education. This includes a variables for those who did not get a High School Diploma, those with a High School Diploma, those with some college, those with a bachelor's degree, and those with more education than a bachelor's degree. 

Another variable of note is *AgeBracket*. This variables indicates what strata of age the respondent is in. Respondents can either be in a strata for those aged 18 to 24, 25 to 34, 35 to 44, 45 to 64, and for those who are 65 or older. These stratas were constructed to match the format of the stratas that are reported in the ACS. In addition, the Chicago Foreign Council also included information about what state a respondent was from, reported in the variable titled *State*. 

There are some checks that we may want to do in order to evaluate whether there was any response bias. In presenting the question represented in variable *Q8_14*. In the survey, this response could have been showed anywhere between first and eighth. We might suspect that the order that Military Intervention is presented will influence the response and create response bias. One method can be checking if the order to the response is likely to change the effect of whether an individual thinks military intervention is effective or not depending on when the respondent is presented with the policy choice of military intervention. 

```{r}
ChicagoForeignCouncilClean<-ChicagoForeignCouncilClean %>% mutate(
  StatementNumber=as.factor(as.numeric(ifelse(Year==2016,substring(DOV_Q8_14,2,2),
                             substring(DOV_Q8_14,2,3)))))
  #this is being done to adjust for the fact that there is a slight difference in how statement order was coded. 
```

```{r, fig.cap="Proportion of Belief in Effectiveness of War"}
ggplot(ChicagoForeignCouncilClean,aes(x=StatementNumber,fill=ProWarFactor))+geom_bar(position=position_fill())+xlab("Position that the Statement was Shown In")+ylab("Proportion of Respondents")+scale_fill_discrete(name = "Pro War Factor", labels = c("Military Intervention is not Effective","Military Intervention is Effective"))
```

Figure 1 illustrates the response of the effectiveness of war, based on the Variable *ProWarFactor*. There is not a lot of variation in the responses of the effectiveness of war depending on the position that the statement was shown in. For instance, we can see that people who were shown this statement earlier may report being more in favor of war, as opposed to those who were asked about military intervention later. However, it appears like the position that the statement was shown in does not carry a significant level of bias, and therefore we can consider that source of response bias as insignificant. 

We can also observe other relationships in our data. One particular question might be whether individuals have different levels of support based on what region they live in. Different cultural values and different regional relationships with the military may determine the different levels of support for military conflict. For instance, Karol and Miguel (2007) tested whether different regions had different levels of political support for reelecting George W. Bush based on the number of casualties in Iraq, based on the speculation that different geographic regions had different relationships with the War. Therefore, observing the prowar and antiwar levels of support within each U.S. region may be important to determining if there is a different level of support depending on geographic region. 

```{r, fig.cap="Belief in the Effectiveness of War by Region of Residence"}
ggplot(ChicagoForeignCouncilClean,aes(x=Region9,fill=ProWarFactor))+geom_bar(position=position_fill())+xlab("Region the Respondent Lives In")+ylab("Proportion of Respondents")+scale_fill_discrete(name = "Pro War Factor", labels = c("Military Intervention is not Effective","Military Intervention is Effective"))+theme(axis.text.x=element_text(angle=90))
```

On Figure 2, we are able to see that there does appear to be some slight differences between different regions in determining the pro and anti war support for the effectiveness of war. The New England region has less support for conflict than the other regions. However, the West-South Central region and the East-South Central Region both tend to be more supportive of conflict than other regions. However, the significance of these responses is not clear based on Figure 2. 

In addition, we are able to observe whether there are differences in pro war and anti war sentiment based on education. This is observed in Figure 3, which indicates that there is some correlation between education level and belief in the effectiveness of war. For people who did not receive an high school diploma, roughly 75% of respondents believed that military intervention is an effective method to achieve the U.S's foreign policy goals. However, for those with a postgraduate degree, about 50% of respondents believed that military intervention is likely to achieve the U.S's foreign policy goals. In addition, Figure 4 illustrates that there is some potential relationship between age and support for military intervention. Those who were between ages 18-24 and 45-64 are more likely support intervention, relative to other age brackets. However, this relationship does not appear to be as strong as other relationships. 

```{r, fig.cap="Belief in the Effectiveness of War by Level of Education"}

ggplot(ChicagoForeignCouncilClean,aes(x=EducationBracket3,fill=ProWarFactor))+geom_bar(position=position_fill())+theme(axis.text.x=element_text(angle=90))+xlab("Level of Education")+ylab("Proportion of Respondents")+scale_fill_discrete(name = "Pro War Factor", labels = c("Military Intervention is not Effective","Military Intervention is Effective"))
```

```{r, fig.cap="Belief in the Effectiveness of War by Age"}
ggplot(ChicagoForeignCouncilClean,aes(x=AgeBracket,fill=ProWarFactor))+geom_bar(position=position_fill())+xlab("Level of Education")+ylab("Proportion of Respondents")+scale_fill_discrete(name = "Pro War Factor", labels = c("Military Intervention is not Effective","Military Intervention is Effective"))
```

Another dataset that was used in this analysis is the American Community Survey. The American Community Survey, or ACS, is a survey that has information on individuals and households throughout the country. In particular, this data focuses on the demographics, occupations, education and other background info of any respondents. The data that was used in this paper was the summary statistic named *B15001*, from the 5-Year ACS between 2015 and 2019. This data includes the raw count of number of respondents who were in a certain strata defined by gender, education level and age bracket. These stratas are pairwise disjoint, as it would require individuals to belong to multiple brackets. Then, I created a new variable, titled *TVP*, standing for Total Voting Population. This was the sum of all of the stratas. I then divided each strata by the variable *TVP*, in order to get an estimation of the proportion of each strata within each state.

The ACS does have a few problems with it that make it a suboptimal resource in order to estimate proportions. The ACS does not ask questions about values such as what political party an individual identifies with, or what foreign policy goals the U.S. should have. These questions may be important in relation to pro and anti war sentiment. These problems will be of particular concern during the implementation of a Multilevel Regression with Post Stratification model. 


### Methods 

This paper will focus on using a Multilevel Regression with Poststratification, or MRP. A Multilevel Regression with Post Stratification is a method to estimate public opinion for areas that are smaller than the national level, such as individual states. It is highly unlikely that there will be multiple state surveys that will all ask the same questions using similar wording and surveying methods. Because of this, statisticians have developed strategies to use national level opinion polls to estimate public opinion for smaller geographic areas. One method is disaggregation, which is where national surveys are pooled in order to calculate public opinion. However, MRP has become an alternative method to disaggregation. MRP has been shown to outperform disaggregation with small and medium sized samples, and can estimate state public opinion with a single large national poll of roughly 1,400 respondents(Gelman, 2018). MRP is better suited for estimating public opinion issues that are swayed heavily by circumstances. In addition, MRP is useful for estimating the responses in smaller states that do not have a large number of respondents who reside in those states. Because of these advantages, building an MRP model is preferable to using a model of disaggregation to estimate the beliefs on the effectiveness of war in each U.S. State. Multilevel regression with Poststratification has been used frequently by statisticians to estimate public opinion by geographic area. For instance, Bohr(2014) used MRP to estimate the probability of an individual in each U.S. county believing in Climate Change, and understanding their preferences for environmental policy. In addition, Wang (2014) used MRP in order to estimate the voters preferences for the U.S. election in 2012 by using surveys submitted through the online platform Xbox Live, which estimated the share of votes to Barack Obama with a margin of error of .6 percentage points. 

There are a few steps needed in order to create an MRP. First, data needs to be collected that focuses on public opinion data, and different potential predictors. Next, there would need to be census data collected in order to estimate the proportion of different stratas in each state. We would also need to estimate the probability of believing U.S. intervention is effective within each strata based on our public opinion data, using a logistic regression from the Chicago Council Surveys. Then, using our estimates of the probability of any person within a strata being pro war, we poststratify these models using the proportional size of the strata relative to the rest of the state. 

One important detail in an MRP is that we are required to have the design of the logistic regression and the design of the ACS must be cohesive in order to effectively implement an MRP. An MRP works because it is accurately able to assign each predicted response based on our regression to our weights for poststratification. Therefore, there would be significant problems in using a Multilevel Regression with Post Stratification if the multilevel regression includes terms that are not included in poststratify weights. This would result in us having predicted response probabilities without any understanding of what the approximate weights of these responses will be. 

Therefore, in building our logistical regression, we will attempt to reduce the AIC and we will only build a model where we can also estimate the weights of these different responses based on the ACS data. In addition, the model that we analyze will also focus on the most important aspects that may have been identified in our data section. For instance, one important variable to use in our regressions would be education. Education level is a variable that shows a clear relationship to pro vs. antiwar sentiment. There are roughly 1000 different distinct counts that exist in the ACS data. However, only about 30 different types of counts include educational attainment as a key variable. In addition, very few of these variables account for the full voting aged population. 

The best model that we could find that includes variables that could be weighted in the census was a model which used educational attainment, gender, and age brackets. However, the state was also used as a random effect. This model produced the smallest AIC of any adequate model that was built in this experiment, at a value of 6130.953[1]. We can therefore write the estimated model as a two part section. The first part represents our Post-stratification, where we multiply the probability of support of pro war by each strata within the state by the probability of any given person in that state being within that strata. We then sum the product of all these probabilities in order to estimate the probability of support within each state. The second line through fourth lines represents our multilevel model, which includes a random effect for the State, in order to account for variations in public opinion within each state that are not accounted for by our model. Finally, our estimation of the probability of being within each strata is defined by calculating the percent of people within each state $j$, who were in Strata $i$ as a percent of the total voting population. 


\begin{flalign}
& P(\theta_{j}=1|\text{State=j})=\sum_{i=1}^{50}P(\theta_{ij}=1|\text{Strata}=i)*P(\text{Strata}=i|\text{State}=J) &\\
& P(\theta_{ij}=1|\text{Strata}_{j}=i)=\text{logit}^{-1}(\alpha+\beta_{1}*\text{Male}_{i}+\beta_{2}*\text{High School Degree}_{i} &\\
& +\beta_{3}*\text{Some College}_{i}+\beta_{4}*\text{Bachelor Degree}_{i}+\beta_{5}*\text{Graduate Degree}_{i}+\beta_{6}*\text{25 to 34}_{i} &\\
& +\beta_{7}*\text{35 to 44}_{i}+\beta_{8}*\times{45 to 64}_{i}+\beta_9*\text{65+}_{i}+u_{j}+\epsilon{ij}) &\\
& u_{j}\sim \mathcal{N}(0,\,\sigma_{u}^{2}) &\\
& \epsilon{ij}\sim \mathcal{N}(0,\,\sigma_{\epsilon}^{2}) &\\
& P(\text{Strata}=i|\text{State}=J)=\frac{\text{Population in Strata I in State j}}{\text{Total Voting Population in State J}} &
\end{flalign}

$\theta$ represents whether an individual believes that war is effective or ineffective at achieving the U.S.'s policy goals. $\alpha$ represents the intercept, which would calculate the probability a Women who is between the ages of 18 to 24 with less than a high school education believes that war is effective. Each of the subsequent $\beta$'s then represent the effect of individual effects, such as identifying as a man, or having a Graduate Education, on pro vs. antiwar sentiment. The value $u_j$ is the random effect that being within a certain state has on their beliefs of war, while $\epsilon_{ij}$ is the random error term. 

By construction, our stratas will be pairwise disjoint and they will cover the voting aged population. The stratas are broken up into categories based on age, sex, and educational obtainment. In addition, it is not possible for an individual in the voting age population to not fit into any of the stratas, or for them to fit into multiple stratas. This is important to ensuring that our MRP model will be successful in estimating the probability of an individual's beliefs on war within a certain state. 

This paper will also build a logistic regression under a Bayesian framework. This would require us to set our priors. These priors would be based on the background research, mostly from the regressions that are in Gelpi and Feaver (2009). Using logitsic regressions on public opinion on conflict, we should be able to have an estimate of 






### Frequentist Results  

```{r, fig.cap="Estimates of Fixed Effects",fig.width=6}
M25Table<-summary(M25)$coefficient
rownames(M25Table)<-c("Intercept","Male","High School Graduate","Some College","Bachelor's Degree","Graduate Degree","Age 25 to 34","Age 35 to 44","Age 45 to 64","Age 65 or older")
kable(M25Table,digits = 4,format="pipe",caption = "Estimates of Fixed Effects")
```


```{r}
plot_usmap(data = metadataStateGIS2, values="EstimatedProbability",color="white")+scale_fill_continuous(name="% who Believe that War is Effective",label= scales::comma)+theme(legend.position="right")
```

```{r}
ggplot(data=df2,aes(x=Number.Sampled,y=SSR,label=State))+geom_point()+geom_text_repel(size=3)+theme_minimal()+xlab("Number of Respondents from Each Sttae")+ylab("Squared Difference of Estimates of Beliefs on War")
```



The model estimates that Republican challengers with no issue pages, an ideology of 0, running in a district with no demographic heterogeneity will have communication ambiguity of -0.749305. For each additional point in ideology for Republicans, the model estimates a 0.012945 point increase in communication ambiguity after accounting for all other fixed effects. However, it should also be noted that this result is not statistically significant, with a large p-value of 0.45. Democrats are estimated to have communication ambiguity 0.047871 less than Republicans after accounting for all other fixed effects. Incumbents are estimated to have communication ambiguity 0.117505 less than challengers after accounting for all other fixed effects. For each additional point in a district's demographic heterogeneity, the model estimates a 0.815260 point increase in communication ambiguity after accounting for all other fixed effects. For each additional issue page on a candidate's website, the model estimates a 0.015542 point decrease in communication ambiguity after accounting for all other fixed effects. For each additional point in ideology, the model estimates that Democrats have an additional 0.100959 point increase in communication ambiguity over Republicans. The model estimates that the standard deviation in communication ambiguity across districts is 0.007862 after accounting for all fixed effects.



### Bayesian Results




### Discussion and Conclusions   

In this paper, we saw that ambiguity does differ with an interaction between a candidate's party identification and their ideology. Given a p-value of roughly zero for `ideology:democrat`, we feel confident that Republicans have a different change in ambiguity depending on ideology than Democrats. The estimate for this variable is 0.100959 and indicates that Democrats become more ambiguous per increase in ideology than Republicans. This connects to the theory from Milita, Simas, Ryan, and Krupnikov (2017) that depending on party, candidates may feel more comfortable with the idea that voters rely on party heuristics when faced with ambiguous language. Our results add evidence to Shesle's research that incumbents tend to have greater clarity than challengers overall, potentially because they are constrained by past voting behavior, greater media scrutiny, and previous position statements (Shepsle, 1972). The model estimate for `incumbent` is -0.117505, with a p-value of nearly zero, indicating we can be very confident incumbents tend to be more clear. Our model does agree with and provide further evidence to Chap et al. that as a district becomes more demographically heterogeneous, ambiguity increases. We see an estimate of 0.815260 for `demHeterogeneity` and a p-value that was roughly zero. Finally, we see statistical evidence of a relationship between the number of issue pages on a candidate's website and less ambiguous language, albeit not a dramatic decrease. The estimate for `totalIssuePages` is -0.015542 with a p-value of approximately zero. This answers our last research question following (Drucker et al. 2004) who concluded that there is little political incentive to address an issue ambiguously when avoidance will do. When candidates do address an issue, they are more likely to be clear about it.

Studies of ambiguity in political communication could benefit from a greater understanding of political success with our research questions in mind. Since the primary driver for most politicians is to win the election, it would be fascinating to consider vote shares between candidates. Other interesting directions for this research would be to compile data from many more election cycles to track individual candidates, parties, and other variables over time. This could add nuance to interactions between party and ideology depending on broader public opinion on generic ballots and control of the white house. For example, a party in 2014 may have been okay with voters relying on heuristics, if the public attitudes towards them were favorable, and opted for more ambiguous language. But generally opinions change for parties and candidates, especially depending on who controls the white house.

It is clear that certain candidate- and district-level factors lead to more ambiguous political communications. Going forward, it may be beneficial to our democracy to consider what, if any, constituent-induced factors contribute to the ambiguity of a candidate's communications. That research may give greater agency to voters to shape political discussions and help strengthen our democracy.


\newpage 

### References

Alexander, R. (2022). Telling Stories with Data. https://tellingstorieswithdata.com/

American National Election Studies. 2021. ANES 2020 Time Series
Study Preliminary Release: Combined Pre-Election and Post-Election
Data [dataset and documentation]. March 24, 2021 version.
www.electionstudies.org

British Broadcasting Corporation. (2014, November 11). The teenage soldiers of World War One. BBC News. Retrieved May 20, 2022, from https://www.bbc.com/news/magazine-29934965 

Brown University. (2021, September 1). Costs of the 20-Year War on terror: $8 trillion and 900,000 deaths. Brown University. Retrieved May 17, 2022, from https://www.brown.edu/news/2021-09-01/costsofwar 

Bohr, J. (2014). Public Views on the Dangers and Importance of Climate Change: Predicting Climate Change Beliefs in the United States through income moderated by party identification. Climate Change, 126, 217–227.

Gallup, G. (1942). How Important is Public Opinion in Time of War. Proceedings of the American Philosophical Society, 85(5), 440–444.

Gelman, A., & Little, T. (1997). Poststratication Into Many Categories Using Hierarchical Logistic Regression. Survey Methodology. http://www.stat.columbia.edu/~gelman/research/published/poststrat3.pdf

Gelman, A., Lax, J., Phillips, J., Gabry, J., & Trangucci, R. (2018). Using Multilevel Regression and Poststratification to Estimate Dynamic Public Opinion. Columbia. http://www.stat.columbia.edu/~gelman/research/unpublished/MRT(1).pdf

Gelpi, C., Feaver, P., & Reifler, J. (2009). Paying the Human Costs of War. Princeton University Press.

Haas, R. (1994). Intervention: The Use of American Military Force in the Post-Cold War World. Carnegie Endowment for International Peace.

Jentleson, B. W. (1992). The Pretty Prudent Public: Post Post-Vietnam American Opinion on the Use of Military Force. International Studies Quarterly, 36(1), 49–73. https://doi.org/10.2307/2600916

Johnson, A., Ott, M., & Dogucu, M. (2021). Bayes Rules! An Introduction to Applied Bayesian Modeling. Chapman and Hall.

Karol, D., & Miguel, E. (2007). The Electoral Cost of War: Iraq Casualties and the 2004 Presidential Election. The Journal of Politics, 69(3), 633–648.

Kastellec, J., Lax, J., & Phillips, J. (2019). Estimating State Public Opinion With Multi-Level Regression and Poststratification using R. Princeton.

Khazan, O. (2013, September 4). What are the big factors determining whether Americans support war? The Atlantic. Retrieved March 29, 2022, from https://www.theatlantic.com/politics/archive/2013/09/what-are-the-big-factors-determining-whether-americans-support-war/279290/-sets-box-office-record 


Lieberfeld, D. (2008). What Makes An Effective Antiwar Movement? Theme-Issue Introduction. International Journal of Peace Studies, 13(1), 1–14. http://www.jstor.org/stable/41852966

Smeltz, Dina, Friedhoff, Karl, Kafura, Craig J., Holyk, Gregory, and Busby, Joshua W. 2016 Chicago Council Survey of American Public Opinion on U.S. Foreign Policy. Ann Arbor, MI: Inter-university Consortium for Political and Social Research [distributor], 2018-04-13. https://doi.org/10.3886/ICPSR36806.v1

Smeltz, Dina, Daalder, Ivo, Friedhoff, Karl, and Kafura, Craig. 2017 Chicago Council Survey of American Public Opinion on U.S. Foreign Policy. Inter-university Consortium for Political and Social Research [distributor], 2021-06-21. https://doi.org/10.3886/ICPSR37970.v1

Smith, C., & Lindsay, J. M. (2003, June 1). Rally 'Round the flag: Opinion in the United States before and after the Iraq War. Brookings. Retrieved March 29, 2022, from https://www.brookings.edu/articles/rally-round-the-flag-opinion-in-the-united-states-before-and-after-the-iraq-war/ 

Wang,W., et al., Forecasting elections with non-representative polls. International Journal of Forecasting (2014), http://dx.doi.org/1-.1016/j.ijforecast.2014.06.001


\newpage

## Appendix

[1] There were other models that did produce AIC. However, these would not have allowed us to get a comprehensive set of weights from the ACS. For instance, some of these models would have produced estimations that we would not have any adequate weights to use in order to poststratify, according to the ACS summary statistics. Another case could be seen by the Model titled "M25b". This model included the effect of ethnicity. However, it would have not allowed us to provide weights for any individual who was between the ages of 18 and 25. This would be a large chunk of the voting population that the model would not have adequate weights for, which would be a problem. 


[2] In some of our data wrangling, we chose to switch the sign of the ambiguity variable in the dataset. Previously, it was higher scores that indicated higher clarity. However, because ambiguity is the response variable and the variable is titled 'ambiguity' we thought it made more sense for analysis to switch these around. 

This is important for two reasons: First, any outside analysis that a person sees about Wordscores software will seem to draw the opposite conclusions; this is not the case, but the language prioritizes clarity over ambiguity. And second, this mutation was made after beginning work on our graphics and may not be reflected as clearly as possible in our analysis. This footnote serves to hopefully dispel any confusion. 

